{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc('figure', figsize=(15, 5))\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from timeit import default_timer as timer\n",
    "import pickle\n",
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer\n",
    "from numpy.random import RandomState\n",
    "from hyperopt import STATUS_OK\n",
    "import csv\n",
    "import ast\n",
    "from Utils_pfs import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_test = pd.read_csv(r'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"full_data_2.pkl\", \"rb\") as input_file:\n",
    "    full_data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_cat = create_cv_sets2([9,21,33], full_data, sales_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    global ITERATION\n",
    "    ITERATION +=1\n",
    "    print('ITERATION: %d' %(ITERATION))\n",
    "    print('params: ', params)\n",
    "    start = timer()\n",
    "    rf = RandomForestRegressor(n_estimators = 50, max_depth = params['max_depth'], max_features = params['max_features'], \n",
    "                               min_samples_leaf=params['min_samples_leaf'], n_jobs = -1)\n",
    "    rf.fit(dict_cat['train'], dict_cat['train_y'])\n",
    "    loss = error(rf.predict(dict_cat['val']), dict_cat['val_y'])\n",
    "    train_time = timer()-start\n",
    "    print('loss: %.5f' %(loss))\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([ITERATION, loss, params, train_time])\n",
    "    return {'iteration': ITERATION, 'loss': loss, 'params': params,   \n",
    "            'train_time': train_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_space = {\n",
    "    'max_depth': hp.choice('subsample', np.arange(1,11,1, dtype = int)),\n",
    "    'max_features': hp.quniform('max_features', 0.05, 1, 0.05),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(10, 101, 5, dtype = int))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'max_features': 0.5, 'min_samples_leaf': 95}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(params_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_file = 'rf_trials_pfs4.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['iteration', 'loss', 'params', 'train_time'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = hyperopt.Trials()\n",
    "global  ITERATION\n",
    "ITERATION = 0\n",
    "best = hyperopt.fmin(\n",
    "    objective,\n",
    "    space=params_space,\n",
    "    algo=hyperopt.tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials,\n",
    "    rstate=RandomState(ITERATION)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_results = pd.read_csv('rf_trials_pfs4.csv')\n",
    "rf_results.sort_values('loss', ascending=True,inplace = True)\n",
    "rf_results.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>iteration</th>\n",
       "      <th>loss</th>\n",
       "      <th>params</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>1.652485</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.75, 'min_s...</td>\n",
       "      <td>617.687029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>1.653236</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.65, 'min_s...</td>\n",
       "      <td>532.923826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>1.653618</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.65, 'min_s...</td>\n",
       "      <td>531.906359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>1.653962</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.55, 'min_s...</td>\n",
       "      <td>458.894292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>1.654012</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.75, 'min_s...</td>\n",
       "      <td>618.132501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  iteration      loss  \\\n",
       "0     31         32  1.652485   \n",
       "1     68         69  1.653236   \n",
       "2     94         95  1.653618   \n",
       "3     58         59  1.653962   \n",
       "4     86         87  1.654012   \n",
       "\n",
       "                                              params  train_time  \n",
       "0  {'max_depth': 10, 'max_features': 0.75, 'min_s...  617.687029  \n",
       "1  {'max_depth': 10, 'max_features': 0.65, 'min_s...  532.923826  \n",
       "2  {'max_depth': 10, 'max_features': 0.65, 'min_s...  531.906359  \n",
       "3  {'max_depth': 10, 'max_features': 0.55, 'min_s...  458.894292  \n",
       "4  {'max_depth': 10, 'max_features': 0.75, 'min_s...  618.132501  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params = ast.literal_eval(rf_results.loc[0, 'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'max_features': 0.75, 'min_samples_leaf': 25}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse with max_depth = 15 is 1.5890628824680237\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 50, max_depth = 15, max_features = best_params['max_features'], \n",
    "                               min_samples_leaf=best_params['min_samples_leaf'], n_jobs = -1)\n",
    "rf.fit(dict_cat['train'], dict_cat['train_y'])\n",
    "print('rmse with max_depth = 15 is {}'.format(error(rf.predict(dict_cat['val']), dict_cat['val_y'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse with max_depth = 20 is 1.5795238900710495\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 50, max_depth = 20, max_features = best_params['max_features'], \n",
    "                               min_samples_leaf=best_params['min_samples_leaf'], n_jobs = -1)\n",
    "rf.fit(dict_cat['train'], dict_cat['train_y'])\n",
    "print('rmse with max_depth = 20 is {}'.format(error(rf.predict(dict_cat['val']), dict_cat['val_y'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_months = np.arange(28,34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for month 28\n",
      "training for month 29\n",
      "training for month 30\n",
      "training for month 31\n",
      "training for month 32\n",
      "training for month 33\n"
     ]
    }
   ],
   "source": [
    "stack_x = []\n",
    "for i in stack_months:\n",
    "  data_train_x = full_data.loc[full_data['date_block_num']<i,:].copy()\n",
    "  data_test_x = full_data.loc[full_data['date_block_num']==i,:].copy()\n",
    "  data_train_x.drop('cnt_shop_item', axis = 1, inplace = True)\n",
    "  data_test_x.drop('cnt_shop_item', axis = 1, inplace = True)\n",
    "  data_train_y = full_data.loc[full_data['date_block_num']<i,'cnt_shop_item'].copy()\n",
    "  data_test_y = full_data.loc[full_data['date_block_num']==i,'cnt_shop_item'].copy()\n",
    "  print('training for month', i)\n",
    "  rf_stack = RandomForestRegressor(n_estimators = 50, max_depth = 20, max_features = best_params['max_features'], \n",
    "                                   min_samples_leaf=best_params['min_samples_leaf'], n_jobs = -1)\n",
    "  rf_stack.fit(data_train_x, data_train_y)\n",
    "  stack_x.extend(np.squeeze(rf_stack.predict(data_test_x)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('Submission Time Series/Stacking/rf_train_level2.csv', stack_x, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
       "           max_features=0.75, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=25, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_x = pd.concat([dict_cat['train'], dict_cat['val']], axis=0)\n",
    "stack_y = pd.concat([dict_cat['train_y'], dict_cat['val_y']], axis = 0)\n",
    "rf_stack = RandomForestRegressor(n_estimators = 50, max_depth = 20, max_features = best_params['max_features'], \n",
    "                                 min_samples_leaf=best_params['min_samples_leaf'], n_jobs = -1)\n",
    "rf_stack.fit(stack_x, stack_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_level2_pred = rf_stack.predict(dict_cat['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_level2_pred_y = stack_level2_pred-1\n",
    "#stack_level2_pred_y = create_test_data(stack_level2_pred_y, dict_cat)\n",
    "np.savetxt('Submission Time Series/Stacking/rf_test_level2.csv', stack_level2_pred_y, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('Submission Time Series/Stacking/rf_final.pkl','wb') as handle:\n",
    "    pickle.dump(rf_stack,handle,protocol=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
