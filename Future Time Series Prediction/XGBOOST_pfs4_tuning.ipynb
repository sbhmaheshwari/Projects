{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-7.3.0-posix-seh-rt_v5-rev0\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc('figure', figsize=(15, 5))\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from timeit import default_timer as timer\n",
    "import pickle\n",
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "import seaborn as sns\n",
    "from numpy.random import RandomState\n",
    "from hyperopt import STATUS_OK\n",
    "import csv\n",
    "import ast\n",
    "from Utils_pfs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_test = pd.read_csv(r'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"full_data_2.pkl\", \"rb\") as input_file:\n",
    "    full_data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_cat = create_cv_sets2([9,21,33], full_data, sales_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2.52364\tval-rmse:2.7565\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 20 rounds.\n",
      "[100]\ttrain-rmse:1.60392\tval-rmse:1.72258\n",
      "[200]\ttrain-rmse:1.55306\tval-rmse:1.68639\n",
      "Stopping. Best iteration:\n",
      "[213]\ttrain-rmse:1.54882\tval-rmse:1.68014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(learning_rate = 0.3, n_estimators = 1000, max_depth = 3, min_child_weight = 1, gamma = 0, \n",
    "                     subsample = 0.8, colsample_bytree=0.8, eval_metric='rmse', seed = 0, n_jobs = -1)\n",
    "xgtrain = xgb.DMatrix(dict_cat['train'], dict_cat['train_y'])\n",
    "xgval = xgb.DMatrix(dict_cat['val'], dict_cat['val_y'])\n",
    "xgb_params = model.get_xgb_params()\n",
    "watchlist = [(xgtrain, 'train'), (xgval, 'val')]\n",
    "xgbresults = xgb.train(xgb_params, xgtrain, num_boost_round = 1000, evals = watchlist,\n",
    "                          early_stopping_rounds = 20, verbose_eval = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_y = xgbresults.predict(xgb.DMatrix(dict_cat['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = sales_test['item_id'].isin(dict_cat['train']['item_id']) & sales_test['shop_id'].isin(dict_cat['train']['shop_id'])\n",
    "test_y = [test_y[j] if test_ids[j] else 0 for j in range(len(test_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission_file(test_y, 'xgb_1', sales_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    global ITERATION\n",
    "    ITERATION +=1\n",
    "    print('ITERATION: %d' %(ITERATION))\n",
    "    print('params: ', params)\n",
    "    model = XGBRegressor(learning_rate = 0.2, max_depth = params['depth'], \n",
    "                         min_child_weight = params['min_child_weight'], gamma = params['gamma'], \n",
    "                         subsample = params['subsample'], colsample_bytree=params['colsample_bytree'], \n",
    "                         eval_metric='rmse', seed = 24, n_jobs = -1)\n",
    "    start = timer()\n",
    "    srtc = []\n",
    "    xgtrain = xgb.DMatrix(dict_cat['train'], dict_cat['train_y'])\n",
    "    xgval = xgb.DMatrix(dict_cat['val'], dict_cat['val_y'])\n",
    "    xgb_params = model.get_xgb_params()\n",
    "    watchlist = [(xgtrain, 'train'), (xgval, 'val')]\n",
    "    xgbresults = xgb.train(xgb_params, xgtrain, num_boost_round = 5000, evals = watchlist, \n",
    "                           early_stopping_rounds = 50, verbose_eval = False)\n",
    "    n_tree = xgbresults.best_ntree_limit\n",
    "    print('n_tree: {}'.format(n_tree))\n",
    "    srtc.append(error(xgbresults.predict(xgb.DMatrix(dict_cat['val'])), dict_cat['val_y']))\n",
    "    train_time = timer()-start\n",
    "    loss = np.mean(srtc)\n",
    "    print('loss: %.5f' %(loss))\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([ITERATION, loss, params, train_time, n_tree])\n",
    "    return {'iteration': ITERATION, 'loss': loss, 'params': params,   \n",
    "            'train_time': train_time, 'n_trees': n_tree, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_space = {\n",
    "    'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.7, 1, 0.05),\n",
    "    'gamma': hp.quniform('gamma', 0, 1, 0.05),\n",
    "    'depth': hp.choice('depth',np.arange(1,16, dtype=int)),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1,15,2),\n",
    "    'eval_metric': 'rmse',\n",
    "    'objective': 'reg:linear'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.9,\n",
       " 'depth': 11,\n",
       " 'eval_metric': 'rmse',\n",
       " 'gamma': 0.2,\n",
       " 'min_child_weight': 10.0,\n",
       " 'objective': 'reg:linear',\n",
       " 'subsample': 0.15000000000000002}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(params_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_file = 'xgboost_trials_pfs4.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['iteration', 'loss', 'params', 'train_time', 'n_trees'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = hyperopt.Trials()\n",
    "global  ITERATION\n",
    "ITERATION = 20\n",
    "best = hyperopt.fmin(\n",
    "    objective,\n",
    "    space=params_space,\n",
    "    algo=hyperopt.tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials,\n",
    "    rstate=RandomState(ITERATION)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.75,\n",
       " 'depth': 12,\n",
       " 'eval_metric': 'rmse',\n",
       " 'gamma': 0.65,\n",
       " 'min_child_weight': 14.0,\n",
       " 'objective': 'reg:linear',\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_tune_results = pd.read_csv('xgboost_trials_pfs4.csv')\n",
    "xgb_tune_results.sort_values('loss', ascending=True, inplace=True)\n",
    "xgb_tune_results.reset_index(inplace = True)\n",
    "best_params = ast.literal_eval(xgb_tune_results.loc[0, 'params'])\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2.5705\tval-rmse:2.82747\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:1.30546\tval-rmse:1.56531\n",
      "[100]\ttrain-rmse:1.25864\tval-rmse:1.56444\n",
      "Stopping. Best iteration:\n",
      "[62]\ttrain-rmse:1.29003\tval-rmse:1.56205\n",
      "\n",
      "382.14868\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(learning_rate = 0.2, max_depth = best_params['depth'], \n",
    "                         min_child_weight = 100, gamma = best_params['gamma'], \n",
    "                         subsample = best_params['subsample'], colsample_bytree=best_params['colsample_bytree'], \n",
    "                         eval_metric='rmse', seed = 24, n_jobs = -1)\n",
    "xgtrain = xgb.DMatrix(dict_cat['train'], dict_cat['train_y'])\n",
    "xgval = xgb.DMatrix(dict_cat['val'], dict_cat['val_y'])\n",
    "xgb_params = model.get_xgb_params()\n",
    "watchlist = [(xgtrain, 'train'), (xgval, 'val')]\n",
    "xgbresults = xgb.train(xgb_params, xgtrain, num_boost_round = 5000, evals = watchlist, \n",
    "                       early_stopping_rounds = 50, verbose_eval = 50)\n",
    "print(error(xgbresults.predict(xgb.DMatrix(dict_cat['val'])), dict_cat['val_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2.57637\tval-rmse:2.83549\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:1.3586\tval-rmse:1.5742\n",
      "[100]\ttrain-rmse:1.30745\tval-rmse:1.55957\n",
      "[150]\ttrain-rmse:1.27773\tval-rmse:1.55391\n",
      "[200]\ttrain-rmse:1.25364\tval-rmse:1.55122\n",
      "[250]\ttrain-rmse:1.23659\tval-rmse:1.55226\n",
      "Stopping. Best iteration:\n",
      "[228]\ttrain-rmse:1.24362\tval-rmse:1.5505\n",
      "\n",
      "379.1354\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(learning_rate = 0.2, max_depth = best_params['depth'], \n",
    "                         min_child_weight = 200, gamma = best_params['gamma'], \n",
    "                         subsample = best_params['subsample'], colsample_bytree=best_params['colsample_bytree'], \n",
    "                         eval_metric='rmse', seed = 24, n_jobs = -1)\n",
    "xgtrain = xgb.DMatrix(dict_cat['train'], dict_cat['train_y'])\n",
    "xgval = xgb.DMatrix(dict_cat['val'], dict_cat['val_y'])\n",
    "xgb_params = model.get_xgb_params()\n",
    "watchlist = [(xgtrain, 'train'), (xgval, 'val')]\n",
    "xgbresults = xgb.train(xgb_params, xgtrain, num_boost_round = 5000, evals = watchlist, \n",
    "                       early_stopping_rounds = 50, verbose_eval = 50)\n",
    "print(error(xgbresults.predict(xgb.DMatrix(dict_cat['val'])), dict_cat['val_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_space = {\n",
    "    'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.7, 1, 0.05),\n",
    "    'gamma': hp.quniform('gamma', 0, 1, 0.05),\n",
    "    'depth': hp.choice('depth',np.arange(1,16, dtype=int)),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 100,1500,50),\n",
    "    'eval_metric': 'rmse',\n",
    "    'objective': 'reg:linear'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = hyperopt.Trials()\n",
    "global  ITERATION\n",
    "ITERATION = 50\n",
    "best = hyperopt.fmin(\n",
    "    objective,\n",
    "    space=params_space,\n",
    "    algo=hyperopt.tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials,\n",
    "    rstate=RandomState(ITERATION)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8500000000000001,\n",
       " 'depth': 10,\n",
       " 'eval_metric': 'rmse',\n",
       " 'gamma': 0.65,\n",
       " 'min_child_weight': 250.0,\n",
       " 'objective': 'reg:linear',\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_tune_results = pd.read_csv('xgboost_trials_pfs4.csv')\n",
    "xgb_tune_results.sort_values('loss', ascending=True, inplace=True)\n",
    "xgb_tune_results.reset_index(inplace = True)\n",
    "best_params = ast.literal_eval(xgb_tune_results.loc[0, 'params'])\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2.58377\tval-rmse:2.8391\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:1.40458\tval-rmse:1.57871\n",
      "[100]\ttrain-rmse:1.35168\tval-rmse:1.56063\n",
      "[150]\ttrain-rmse:1.32544\tval-rmse:1.55575\n",
      "[200]\ttrain-rmse:1.3055\tval-rmse:1.55166\n",
      "[250]\ttrain-rmse:1.28748\tval-rmse:1.5491\n",
      "[300]\ttrain-rmse:1.27214\tval-rmse:1.54785\n",
      "[350]\ttrain-rmse:1.25936\tval-rmse:1.54783\n",
      "Stopping. Best iteration:\n",
      "[332]\ttrain-rmse:1.26264\tval-rmse:1.54721\n",
      "\n",
      "378.75806\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(learning_rate = 0.2, max_depth = best_params['depth'], \n",
    "                         min_child_weight = best_params['min_child_weight'], gamma = best_params['gamma'], \n",
    "                         subsample = best_params['subsample'], colsample_bytree=best_params['colsample_bytree'], \n",
    "                         eval_metric='rmse', seed = 24, n_jobs = -1)\n",
    "xgtrain = xgb.DMatrix(dict_cat['train'], dict_cat['train_y'])\n",
    "xgval = xgb.DMatrix(dict_cat['val'], dict_cat['val_y'])\n",
    "xgb_params = model.get_xgb_params()\n",
    "watchlist = [(xgtrain, 'train'), (xgval, 'val')]\n",
    "xgbresults = xgb.train(xgb_params, xgtrain, num_boost_round = 5000, evals = watchlist, \n",
    "                       early_stopping_rounds = 50, verbose_eval = 50)\n",
    "print(error(xgbresults.predict(xgb.DMatrix(dict_cat['val'])), dict_cat['val_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = xgbresults.predict(xgb.DMatrix(dict_cat['test']))\n",
    "pred = pred-1\n",
    "pred = create_test_data(pred, dict_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission_file(pred, 'xgboost_final', sales_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating data for stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_months = np.arange(28,34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_y = full_data.loc[full_data['date_block_num'].isin(stack_months),'cnt_shop_item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for month 28\n",
      "training for month 29\n",
      "training for month 30\n",
      "training for month 31\n",
      "training for month 32\n",
      "training for month 33\n"
     ]
    }
   ],
   "source": [
    "stack_x = []\n",
    "for i in stack_months:\n",
    "  data_train_x = full_data.loc[full_data['date_block_num']<i,:].copy()\n",
    "  data_test_x = full_data.loc[full_data['date_block_num']==i,:].copy()\n",
    "  data_train_x.drop('cnt_shop_item', axis = 1, inplace = True)\n",
    "  data_test_x.drop('cnt_shop_item', axis = 1, inplace = True)\n",
    "  data_train_y = full_data.loc[full_data['date_block_num']<i,'cnt_shop_item'].copy()\n",
    "  data_test_y = full_data.loc[full_data['date_block_num']==i,'cnt_shop_item'].copy()\n",
    "  \n",
    "  model = XGBRegressor(learning_rate = 0.2, max_depth = best_params['depth'], \n",
    "                       min_child_weight = best_params['min_child_weight'], gamma = best_params['gamma'], \n",
    "                       subsample = best_params['subsample'], colsample_bytree=best_params['colsample_bytree'], \n",
    "                       eval_metric='rmse', seed = 24, n_jobs = -1)\n",
    "  print('training for month', i)\n",
    "  xgtrain = xgb.DMatrix(data_train_x, data_train_y)\n",
    "  xgb_params = model.get_xgb_params()\n",
    "  xgbresults = xgb.train(xgb_params, xgtrain, num_boost_round = 330, verbose_eval = 50)\n",
    "  stack_x.extend(np.squeeze(xgbresults.predict(xgb.DMatrix(data_test_x))).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('Submission Time Series/Stacking/xgboost_train_level2.csv', stack_x, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_x = pd.concat([dict_cat['train'], dict_cat['val']], axis=0)\n",
    "stack_y = pd.concat([dict_cat['train_y'], dict_cat['val_y']], axis = 0)\n",
    "model = XGBRegressor(learning_rate = 0.2, max_depth = best_params['depth'], \n",
    "                     min_child_weight = best_params['min_child_weight'], gamma = best_params['gamma'], \n",
    "                     subsample = best_params['subsample'], colsample_bytree=best_params['colsample_bytree'], \n",
    "                     eval_metric='rmse', seed = 24, n_jobs = -1)\n",
    "xgtrain = xgb.DMatrix(stack_x, stack_y)\n",
    "xgb_params = model.get_xgb_params()\n",
    "xgbresults = xgb.train(xgb_params, xgtrain, num_boost_round = 330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_test_y = xgbresults.predict(xgb.DMatrix(dict_cat['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_test_level2_y = stack_test_y-1\n",
    "#stack_test_level2_y = create_test_data(stack_test_level2_y, dict_cat)\n",
    "stack_test_level2_y = [i if i>0 else 0 for i in stack_test_level2_y]\n",
    "np.savetxt('Submission Time Series/Stacking/xgboost_test_level2_2.csv', stack_test_level2_y, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission_file(stack_test_level2_y, 'xgboost_final', sales_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
