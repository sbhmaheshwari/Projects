{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "from matplotlib import rc\n",
    "rc('figure', figsize=(15, 5))\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from timeit import default_timer as timer\n",
    "import pickle\n",
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer\n",
    "from numpy.random import RandomState\n",
    "from hyperopt import STATUS_OK\n",
    "import csv\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_test = pd.read_csv(r'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data(prediction, dict_cat):\n",
    "  trtv = pd.concat([dict_cat['train'], dict_cat['val']], axis = 0)\n",
    "  test_ids = dict_cat['test']['item_id'].isin(trtv['item_id']) & dict_cat['test']['shop_id'].isin(trtv['shop_id'])\n",
    "  prediction[~test_ids] = 0\n",
    "  return(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test(test):\n",
    "    test = test.loc[(test['shop_id'].isin(sales_test['shop_id']))&(test['item_id'].isin(sales_test['item_id'])),:].copy()\n",
    "    test_pred = test['cnt_shop_item'].copy()\n",
    "    test.drop('cnt_shop_item', axis = 1, inplace = True)\n",
    "    return(test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cv_sets2(months, data):\n",
    "    X_train = data.loc[~data['date_block_num'].isin(months+[34]),:].drop('cnt_shop_item', axis=1)\n",
    "    X_val = data.loc[data['date_block_num'].isin(months),:]\n",
    "    X_val, y_val = create_test(X_val)\n",
    "    X_test = data.loc[data['date_block_num'] == 34,:].drop('cnt_shop_item',axis=1)\n",
    "    y_train = data.loc[~data['date_block_num'].isin(months+[34]),'cnt_shop_item']\n",
    "    return(dict({'train': X_train, 'val': X_val, 'test': X_test, 'train_y': y_train, 'val_y': y_val}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(pred, name):\n",
    "    ID = np.arange(0, sales_test.shape[0]) \n",
    "    new_df = pd.DataFrame({'ID': ID, 'item_cnt_month': pred})\n",
    "    new_df.to_csv('Submission Time Series/'+name+'.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"full_data.pkl\", \"rb\") as input_file:\n",
    "    full_data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1823324, 63)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cat = create_cv_sets2([9,21,33], full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    global ITERATION\n",
    "    ITERATION +=1\n",
    "    print('ITERATION: %d' %(ITERATION))\n",
    "    print('params: ', params)\n",
    "    model = CatBoostRegressor(iterations = 5000, l2_leaf_reg=params['l2_leaf_reg'], learning_rate = 0.2,\n",
    "                             rsm = params['rsm'], random_seed = 24, depth = params['depth'])\n",
    "    start = timer()\n",
    "    model.fit(dict_cat['train'], dict_cat['train_y'], eval_set = (dict_cat['val'], dict_cat['val_y']), \n",
    "              early_stopping_rounds=100, logging_level='Silent')\n",
    "    n_tree = model.tree_count_\n",
    "    loss = model.score(dict_cat['val'], dict_cat['val_y'])\n",
    "    train_time = timer()-start\n",
    "    del model\n",
    "    print('loss: %.5f' %(loss))\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([ITERATION, loss, params, train_time])\n",
    "    return {'iteration': ITERATION, 'loss': loss, 'params': params,   \n",
    "            'train_time': train_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_space = {\n",
    "    'l2_leaf_reg': hyperopt.hp.quniform('l2_leaf_reg', 1, 100, 1),\n",
    "    'rsm': 1 - hp.loguniform('rsm',np.log(0.01) , np.log(0.35)),\n",
    "    'depth': hp.quniform('depth', 5, 16, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 10.0, 'l2_leaf_reg': 99.0, 'rsm': 0.9233874278606713}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(params_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = 'cat_trials_pfs4_2.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "## Write the headers to the file\n",
    "writer.writerow(['iteration', 'loss', 'params', 'train_time'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION: 1\n",
      "params:  {'depth': 16.0, 'l2_leaf_reg': 69.0, 'rsm': 0.9437023664900684}\n"
     ]
    }
   ],
   "source": [
    "trials = hyperopt.Trials()\n",
    "global  ITERATION\n",
    "ITERATION = 0\n",
    "best = hyperopt.fmin(\n",
    "    objective,\n",
    "    space=params_space,\n",
    "    algo=hyperopt.tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials,\n",
    "    rstate=RandomState(ITERATION)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_tune_results = pd.read_csv('cat_trials_pfs4.csv')\n",
    "cat_tune_results.sort_values('loss', ascending=True, inplace=True)\n",
    "cat_tune_results.reset_index(inplace = True)\n",
    "best_params = ast.literal_eval(cat_tune_results.loc[0, 'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 12.0, 'l2_leaf_reg': 42.0, 'rsm': 0.7879629501355983}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the learning rate and n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric iscalculated on every iteration. 'metric_period' is ignored for evaluation metric.\n",
      "0:\tlearn: 2.8338432\ttest: 3.0894248\tbest: 3.0894248 (0)\ttotal: 1.56s\tremaining: 6h 31m 4s\n",
      "200:\tlearn: 1.3618551\ttest: 1.5810148\tbest: 1.5810148 (200)\ttotal: 3m 51s\tremaining: 4h 43m 35s\n",
      "400:\tlearn: 1.2844462\ttest: 1.5742839\tbest: 1.5734050 (392)\ttotal: 7m 27s\tremaining: 4h 31m 17s\n",
      "600:\tlearn: 1.2329980\ttest: 1.5710585\tbest: 1.5706888 (594)\ttotal: 11m 6s\tremaining: 4h 26m 5s\n",
      "800:\tlearn: 1.1922826\ttest: 1.5699336\tbest: 1.5697052 (767)\ttotal: 14m 45s\tremaining: 4h 21m 33s\n",
      "1000:\tlearn: 1.1560746\ttest: 1.5668903\tbest: 1.5668131 (999)\ttotal: 18m 26s\tremaining: 4h 17m 54s\n",
      "1200:\tlearn: 1.1236681\ttest: 1.5658752\tbest: 1.5654592 (1192)\ttotal: 22m 6s\tremaining: 4h 14m 4s\n",
      "1400:\tlearn: 1.0928341\ttest: 1.5651970\tbest: 1.5647866 (1341)\ttotal: 25m 49s\tremaining: 4h 10m 38s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.5647866\n",
      "bestIteration = 1341\n",
      "\n",
      "Shrink model to first 1342 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x2af8c283320>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostRegressor(iterations = 15000, l2_leaf_reg=best_params['l2_leaf_reg'], learning_rate = 0.2,\n",
    "                          rsm = best_params['rsm'], random_seed = 24, depth = best_params['depth'], metric_period = 200)\n",
    "model.fit(dict_cat['train'], dict_cat['train_y'], eval_set = (dict_cat['val'], dict_cat['val_y']), \n",
    "          early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cat_boost_final.pkl','wb') as handle:\n",
    "    pickle.dump(model,handle,protocol=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating data for stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_months = np.arange(28,34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_y = full_data.loc[full_data['date_block_num'].isin(stack_months),'cnt_shop_item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for month 28\n",
      "training for month 29\n",
      "training for month 30\n",
      "training for month 31\n",
      "training for month 32\n",
      "training for month 33\n"
     ]
    }
   ],
   "source": [
    "stack_x = []\n",
    "for i in stack_months:\n",
    "  data_train_x = full_data.loc[full_data['date_block_num']<i,:].copy()\n",
    "  data_test_x = full_data.loc[full_data['date_block_num']==i,:].copy()\n",
    "  data_train_x.drop('cnt_shop_item', axis = 1, inplace = True)\n",
    "  data_test_x.drop('cnt_shop_item', axis = 1, inplace = True)\n",
    "  data_train_y = full_data.loc[full_data['date_block_num']<i,'cnt_shop_item'].copy()\n",
    "  data_test_y = full_data.loc[full_data['date_block_num']==i,'cnt_shop_item'].copy()\n",
    "  \n",
    "  model = CatBoostRegressor(iterations = 1342, l2_leaf_reg=best_params['l2_leaf_reg'], learning_rate = 0.2,\n",
    "                            rsm = best_params['rsm'], random_seed = 24, depth = best_params['depth'])\n",
    "  print('training for month', i)\n",
    "  model.fit(data_train_x, data_train_y, logging_level='Silent')\n",
    "  stack_x.extend(np.squeeze(model.predict(data_test_x)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192351"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stack_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Submission Time Series/Stacking/catboost_train_level2.csv', stack_x, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.8441404\ttotal: 1.03s\tremaining: 22m 58s\n",
      "200:\tlearn: 1.3643436\ttotal: 3m 43s\tremaining: 21m 9s\n",
      "400:\tlearn: 1.2904161\ttotal: 7m 21s\tremaining: 17m 15s\n",
      "600:\tlearn: 1.2371631\ttotal: 11m 2s\tremaining: 13m 36s\n",
      "800:\tlearn: 1.1966821\ttotal: 14m 42s\tremaining: 9m 56s\n",
      "1000:\tlearn: 1.1592731\ttotal: 18m 32s\tremaining: 6m 19s\n",
      "1200:\tlearn: 1.1278170\ttotal: 22m 16s\tremaining: 2m 36s\n",
      "1341:\tlearn: 1.1067424\ttotal: 24m 55s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x2af8c283898>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_x = pd.concat([dict_cat['train'], dict_cat['val']], axis=0)\n",
    "stack_y = pd.concat([dict_cat['train_y'], dict_cat['val_y']], axis = 0)\n",
    "model = CatBoostRegressor(iterations = 1342, l2_leaf_reg=best_params['l2_leaf_reg'], learning_rate = 0.2,\n",
    "                            rsm = best_params['rsm'], random_seed = 24, depth = best_params['depth'])\n",
    "model.fit(stack_x, stack_y, verbose=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_test_y = model.predict(dict_cat['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_test_level2_y = stack_test_y-1\n",
    "#stack_test_level2_y = create_test_data(stack_test_level2_y, dict_cat)\n",
    "stack_test_level2_y = [i if i>0 else 0 for i in stack_test_level2_y]\n",
    "np.savetxt('Submission Time Series/Stacking/catboost_test_level2.csv', stack_test_level2_y, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission_file(stack_test_level2_y, 'catboost_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
